{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "import humanize\n",
    "import os\n",
    "import GPUtil as GPU\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import gc\n",
    "from scipy.special import softmax\n",
    "from simpletransformers.classification import ClassificationModel\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold \n",
    "import sklearn\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import *\n",
    "import re\n",
    "import random\n",
    "import torch\n",
    "pd.options.display.max_colwidth = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_all(seed_value):\n",
    "    random.seed(seed_value) # Python\n",
    "    np.random.seed(seed_value) # cpu vars\n",
    "    torch.manual_seed(seed_value) # cpu  vars\n",
    "    \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
    "        torch.backends.cudnn.deterministic = True  #needed\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_all(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "democrats = pd.read_parquet(\"../10_datasets/democrats\")\n",
    "republicans = pd.read_parquet(\"../10_datasets/neutral.parquet\")\n",
    "neutral = pd.read_parquet(\"../10_datasets/republican.parquet\")\n",
    "df = pd.concat([democrats, republicans, neutral]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[[\"total_post\",\"subreddit\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['democrats', 'NeutralPolitics', 'Republican'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.subreddit.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14506,)\n"
     ]
    }
   ],
   "source": [
    "label_cols = ['democrats', 'NeutralPolitics', 'Republican']\n",
    "l = ['democrats', 'NeutralPolitics', 'Republican']\n",
    "train['label']=train.subreddit.astype('category')\n",
    "Y = train.label.cat.codes\n",
    "train['label']=Y\n",
    "print(Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorical(y, num_classes):\n",
    "    \"\"\" 1-hot encodes a tensor \"\"\"\n",
    "    return np.eye(num_classes, dtype='uint8')[y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = to_categorical(Y, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14506, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(Y[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(l)) :     \n",
    "     train[l[i]] = Y[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 478M/478M [00:19<00:00, 25.5MB/s]\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Downloading: 100%|██████████| 878k/878k [00:00<00:00, 6.96MB/s]\n",
      "Downloading: 100%|██████████| 446k/446k [00:00<00:00, 3.58MB/s]\n",
      "Downloading: 100%|██████████| 1.29M/1.29M [00:00<00:00, 8.58MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many dimensions 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/simpletransformers/classification/classification_model.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, train_df, multi_label, output_dir, show_running_loss, args, eval_df, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    590\u001b[0m                     \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 )\n\u001b[0;32m--> 592\u001b[0;31m             train_dataset = self.load_and_cache_examples(\n\u001b[0m\u001b[1;32m    593\u001b[0m                 \u001b[0mtrain_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m             )\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/simpletransformers/classification/classification_model.py\u001b[0m in \u001b[0;36mload_and_cache_examples\u001b[0;34m(self, examples, evaluate, no_cache, multi_label, verbose, silent)\u001b[0m\n\u001b[1;32m   1797\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1798\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1799\u001b[0;31m             dataset = ClassificationDataset(\n\u001b[0m\u001b[1;32m   1800\u001b[0m                 \u001b[0mexamples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1801\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/simpletransformers/classification/classification_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, tokenizer, args, mode, multi_label, output_mode, no_cache)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mClassificationDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         self.examples, self.labels = build_classification_dataset(\n\u001b[0m\u001b[1;32m    258\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         )\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/simpletransformers/classification/classification_utils.py\u001b[0m in \u001b[0;36mbuild_classification_dataset\u001b[0;34m(data, tokenizer, args, mode, multi_label, output_mode, no_cache)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"classification\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0moutput_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"regression\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many dimensions 'str'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "err=[]\n",
    "y_pred_tot=[]\n",
    "\n",
    "fold=StratifiedKFold(n_splits=5, shuffle=True, random_state=1997)\n",
    "i=1\n",
    "for train_index, test_index in fold.split(train,train['label']):\n",
    "    train1_trn, train1_val = train.iloc[train_index], train.iloc[test_index]\n",
    "    model = ClassificationModel('roberta', 'roberta-base', use_cuda=False,num_labels=4, args={\n",
    "                                                                         'train_batch_size':16,\n",
    "                                                                         'reprocess_input_data': True,\n",
    "                                                                         'overwrite_output_dir': True,\n",
    "                                                                         'fp16': False,\n",
    "                                                                         'do_lower_case': False,\n",
    "                                                                         'num_train_epochs': 4,\n",
    "                                                                         'max_seq_length': 128,\n",
    "                                                                         'regression': False,\n",
    "                                                                         'manual_seed': 1997,\n",
    "                                                                         \"learning_rate\":2e-5,\n",
    "                                                                         'weight_decay':0,\n",
    "                                                                         \"save_eval_checkpoints\": True,\n",
    "                                                                         \"save_model_every_epoch\": False,\n",
    "                                                                         \"silent\": True})\n",
    "    model.train_model(train1_trn)\n",
    "    raw_outputs_val = model.eval_model(train1_val)[1]\n",
    "    raw_outputs_vals = softmax(raw_outputs_val,axis=1)\n",
    "    print(f\"Log_Loss: {log_loss(train1_val['label'], raw_outputs_vals)}\")\n",
    "    err.append(log_loss(train1_val['label'], raw_outputs_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_post</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>label</th>\n",
       "      <th>democrats</th>\n",
       "      <th>NeutralPolitics</th>\n",
       "      <th>Republican</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There's no such thing as free healthcare. Someone has to pay for it. There is, however, something called single-payer healthcare, which is what Medicare For All is - all healthcare is paid for by ...</td>\n",
       "      <td>democrats</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Figures about the deployment of tests ? Trump's lies about the seriousness of this virus ? \\n\\nOr just say you vehemently disagree and will avoid discussing for sake of harmony</td>\n",
       "      <td>democrats</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Money. Personally, I believe the Republicans have been setting this exact system up for the past thirty years. I don't think they care at all about your right to vote or your body or your marriage...</td>\n",
       "      <td>democrats</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I have family members who get their hair cut.\\n\\nDoes that mean they don't wear a mask, and think the coronavirus is a hoax???\\n\\nHow are they hypocrites?\\n\\nIn MOST of the country salons are open...</td>\n",
       "      <td>democrats</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stuttering doesn’t make someone a bad person. Also, if look in the DSM under Narcissistic Personality Disorder, Trump fits all the points and therefore does have an “unsound mind.” Obama/Biden wer...</td>\n",
       "      <td>democrats</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14500</th>\n",
       "      <td>Dark side After many years, my wife finally decided, without me prompting her, to leave the dark side and register Republican.</td>\n",
       "      <td>Republican</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14501</th>\n",
       "      <td>What is it with liberals calling out certain conservatives to go fight in the military, when they would never even step foot in the recruiters office?</td>\n",
       "      <td>Republican</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14503</th>\n",
       "      <td>The Left Lack of Understanding to the Situation in Iraq is Abhorrent Just head on over to the r/politics sub-reddit and see for yourself.\\n\\nThey think Trump and anyone who supports or votes for h...</td>\n",
       "      <td>Republican</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14504</th>\n",
       "      <td>(Serious) 18 year old here, can you guys tell me about what makes the republican party better than the democrats?</td>\n",
       "      <td>Republican</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14505</th>\n",
       "      <td>Kick in the new Year with awkward Biden moments from 2019. And this guy is the front runner..</td>\n",
       "      <td>Republican</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11604 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                    total_post  \\\n",
       "0      There's no such thing as free healthcare. Someone has to pay for it. There is, however, something called single-payer healthcare, which is what Medicare For All is - all healthcare is paid for by ...   \n",
       "1                             Figures about the deployment of tests ? Trump's lies about the seriousness of this virus ? \\n\\nOr just say you vehemently disagree and will avoid discussing for sake of harmony   \n",
       "2      Money. Personally, I believe the Republicans have been setting this exact system up for the past thirty years. I don't think they care at all about your right to vote or your body or your marriage...   \n",
       "3      I have family members who get their hair cut.\\n\\nDoes that mean they don't wear a mask, and think the coronavirus is a hoax???\\n\\nHow are they hypocrites?\\n\\nIn MOST of the country salons are open...   \n",
       "4      Stuttering doesn’t make someone a bad person. Also, if look in the DSM under Narcissistic Personality Disorder, Trump fits all the points and therefore does have an “unsound mind.” Obama/Biden wer...   \n",
       "...                                                                                                                                                                                                        ...   \n",
       "14500                                                                           Dark side After many years, my wife finally decided, without me prompting her, to leave the dark side and register Republican.   \n",
       "14501                                                   What is it with liberals calling out certain conservatives to go fight in the military, when they would never even step foot in the recruiters office?   \n",
       "14503  The Left Lack of Understanding to the Situation in Iraq is Abhorrent Just head on over to the r/politics sub-reddit and see for yourself.\\n\\nThey think Trump and anyone who supports or votes for h...   \n",
       "14504                                                                                        (Serious) 18 year old here, can you guys tell me about what makes the republican party better than the democrats?   \n",
       "14505                                                                                                            Kick in the new Year with awkward Biden moments from 2019. And this guy is the front runner..   \n",
       "\n",
       "        subreddit  label  democrats  NeutralPolitics  Republican  \n",
       "0       democrats      2          0                0           1  \n",
       "1       democrats      2          0                0           1  \n",
       "2       democrats      2          0                0           1  \n",
       "3       democrats      2          0                0           1  \n",
       "4       democrats      2          0                0           1  \n",
       "...           ...    ...        ...              ...         ...  \n",
       "14500  Republican      1          0                1           0  \n",
       "14501  Republican      1          0                1           0  \n",
       "14503  Republican      1          0                1           0  \n",
       "14504  Republican      1          0                1           0  \n",
       "14505  Republican      1          0                1           0  \n",
       "\n",
       "[11604 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1_trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_post</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>label</th>\n",
       "      <th>democrats</th>\n",
       "      <th>NeutralPolitics</th>\n",
       "      <th>Republican</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dude, none of us are impressed by this kind of nonsense. If you and AOC want to convince us, do so by actually getting shit done instead of landing sick burns on twitter.</td>\n",
       "      <td>democrats</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I'm not really disagreeing with you, but exit polling has shown that even in this election roughly 30-35% of Democratic voters care more about someone who aligns with their views instead of the pe...</td>\n",
       "      <td>democrats</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\"You don't need that money for food, only nobles such as I should have money.\"  \\n\\n\\nGood God, I hope this is a \"Let Them Eat Cake\" moment for someone</td>\n",
       "      <td>democrats</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>It’ll be even emptier next time when half those people get sick and are unable to attend his next bullshit session.</td>\n",
       "      <td>democrats</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Even the woman laughed. Stop making things out of nothing. There are plenty of other real things you can harp on.</td>\n",
       "      <td>democrats</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14472</th>\n",
       "      <td>Just wanted you all to know if you say anything remotely negative or off color about the Obamas in r /pics, you will get permanently banned like me.</td>\n",
       "      <td>Republican</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14483</th>\n",
       "      <td>What is the GOP’s justification for denying witnesses and withholding evidence at Trump’s impeachment?</td>\n",
       "      <td>Republican</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14487</th>\n",
       "      <td>Very mad about Colin Kaepernick disrespecting our BRAVE TROOPS.... Quit whining! Just stand up and sing the National Anthem!</td>\n",
       "      <td>Republican</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14498</th>\n",
       "      <td>What is the most evil thing or the worst thing Obama's ever done? You can list more things than just one. We all know he has done many stupid things. \\nAnd also the best thing or the least bad thi...</td>\n",
       "      <td>Republican</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14502</th>\n",
       "      <td>Can somebody send me a link to a website that proves that Soleimani was going to orchestrate an attack in Iraq or to American?</td>\n",
       "      <td>Republican</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2902 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                    total_post  \\\n",
       "6                                   Dude, none of us are impressed by this kind of nonsense. If you and AOC want to convince us, do so by actually getting shit done instead of landing sick burns on twitter.   \n",
       "9      I'm not really disagreeing with you, but exit polling has shown that even in this election roughly 30-35% of Democratic voters care more about someone who aligns with their views instead of the pe...   \n",
       "18                                                     \"You don't need that money for food, only nobles such as I should have money.\"  \\n\\n\\nGood God, I hope this is a \"Let Them Eat Cake\" moment for someone   \n",
       "25                                                                                         It’ll be even emptier next time when half those people get sick and are unable to attend his next bullshit session.   \n",
       "32                                                                                           Even the woman laughed. Stop making things out of nothing. There are plenty of other real things you can harp on.   \n",
       "...                                                                                                                                                                                                        ...   \n",
       "14472                                                     Just wanted you all to know if you say anything remotely negative or off color about the Obamas in r /pics, you will get permanently banned like me.   \n",
       "14483                                                                                                   What is the GOP’s justification for denying witnesses and withholding evidence at Trump’s impeachment?   \n",
       "14487                                                                             Very mad about Colin Kaepernick disrespecting our BRAVE TROOPS.... Quit whining! Just stand up and sing the National Anthem!   \n",
       "14498  What is the most evil thing or the worst thing Obama's ever done? You can list more things than just one. We all know he has done many stupid things. \\nAnd also the best thing or the least bad thi...   \n",
       "14502                                                                           Can somebody send me a link to a website that proves that Soleimani was going to orchestrate an attack in Iraq or to American?   \n",
       "\n",
       "        subreddit  label  democrats  NeutralPolitics  Republican  \n",
       "6       democrats      2          0                0           1  \n",
       "9       democrats      2          0                0           1  \n",
       "18      democrats      2          0                0           1  \n",
       "25      democrats      2          0                0           1  \n",
       "32      democrats      2          0                0           1  \n",
       "...           ...    ...        ...              ...         ...  \n",
       "14472  Republican      1          0                1           0  \n",
       "14483  Republican      1          0                1           0  \n",
       "14487  Republican      1          0                1           0  \n",
       "14498  Republican      1          0                1           0  \n",
       "14502  Republican      1          0                1           0  \n",
       "\n",
       "[2902 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1_val"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "84b1e2213175d1b29c0c106fcfdfa2350458511224f0b9c320f712c5e7a09711"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
